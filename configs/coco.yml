config_name: coco

dataset_name: coco
data_dir: ./data/coco

gpus: '0'
imsize: 256
z_dim: 100
cond_dim: 256
manual_seed: 100
cuda: True
num_workers: 0

output: ./output/coco_demo
mode: 'train'
stamp: 'normal'
state_epoch: 0
epochs: 501
batch_size: 16
nf: 32
ch_size: 3
resume_epoch: 1
resume_model_path: ./output/test_clip3
tensorboard: True
params: False
sc: True

generator:
    lr: 0.0001
    beta1: 0.0
    beta2: 0.9

discriminator:
    lr: 0.0004
    beta1: 0.0
    beta2: 0.9

print_step: 500

model:
    encoder_type: clip
    pre_encoder: "ViT-B/32"
    embedding_dim: 512
    pre_clip: "ViT-B/32"

gen_interval: 1
test_interval: 5
save_interval: 5

truncation: True
trunc_rate: 0.88

sample_times: 1
npz_path: ./data/coco/npz/coco_val256_FIDK0.npz
example_captions: ./example_captions/coco.txt
samples_save_dir: ./samples/coco/
checkpoint:
    load: False
    path: None

save_image: True
val_save_dir: ./vals/coco/

text:
    words_num: 32
    captions_per_image: 5
    damsm_name: ./data/coco/DAMSMencoder/text_encoder100.pth

loss:
    gan_mode: 'hinge'
    clip_match: 4.0
    match_loss: True
    clip_rate: 1.0
    clip_loss: False
    